struct lexer {
	src:StringView,
	index:int,
	col:int
}

proc new_lexer src:ptr -> lexer {
	let src_sv = sv_from(src);
	return lexer(src_sv, 0, 1);
}

proc lexer_delete lxr:lexer -> void {
	delete lxr.src;
	delete lxr;
}

proc lexer_consume lxr:lexer -> int {
	let chr = sv_at(lxr.src, lxr.index);
	lxr.index = lxr.index + 1;
	lxr.col = lxr.col + 1;
	return chr;
}

const NULL_PEEK 4294967295;

proc lexer_peek lxr:lexer -> int {
	if(lxr.index > lxr.src.count) {
		return NULL_PEEK;
	}
	return sv_at(lxr.src, lxr.index);
}

proc lexer_peek_at lxr:lexer offs:int -> int {
	if((lxr.index + offs) > lxr.src.count) {
		return NULL_PEEK;
	}
	return sv_at(lxr.src, lxr.index + offs);
}

struct TmpStr(__global_obj_alloc) {
	used:int,
	capacity:int,
	data:ptr
}

proc new_tmp_str arena:ArenaAllocator size:int -> TmpStr {
	return TmpStr(0, size, arena_take(arena, size));
}

proc tmp_str_realloc str:TmpStr arena:ArenaAllocator size:int -> void {
	str.used = 0;
	str.capacity = size;
	str.data = arena_take(arena, size);
}

proc tmp_str_push str:TmpStr chr:int -> void {
	store8(str.data + str.used, chr);
	str.used = str.used + 1;
	store8(str.data + str.used, 0);
}

proc isspace chr:int -> int {
	if(chr == ' ') { return true; }
	if(chr == 9)   { return true; }
	return false;
}

proc isdigit chr:int -> int {
	if(chr > ('0' - 1)) {
		if(chr < ('9' + 1)) {
			return true;
		}
		return false;
	}
	else {
		return false;
	}
}

proc is_identif chr:int -> int {
	if(chr == '_') {
		return true;
	}
	if(chr < 'A') {
		return false;
	}
	if(chr > 'z') {
		return false;
	}
	if(chr > 'Z') {
		if(chr < 'a') {
			return false;
		}
	}
	return true;
}

const Token_typeIdent       iota;
const Token_typeOpenParen   iota;
const Token_typeCloseParen  iota;
const Token_typeExit        iota;
const Token_typeIntLiteral  iota;
const Token_typeSemi        iota;
const Token_typePlus        iota;
const Token_typeMinus       iota;
const Token_typeStar        iota;
const Token_typeSlash       iota;
const Token_typePrint       iota;
const Token_typeLet         iota;
const Token_typeEq          iota;
const Token_typeIf          iota;
const Token_typeCloseCurly  iota;
const Token_typeOpenCurly   iota;
const Token_typeElse        iota;
const Token_typeElif        iota;
const Token_typeProc        iota;
const Token_typeArrow       iota;
const Token_typeVoid        iota;
const Token_typeInt         iota;
const Token_typeComma       iota;
const Token_typeDoubleColon iota;
const Token_typeReturn      iota;
const Token_typesCount      reset;

struct Token(__global_obj_alloc) {
	_type:int,
	line:int,
	col:int,
	value:ptr,
	file_loc:ptr,
}

proc push_token tokens:ptr index:ptr tok:Token -> void {
	store32(tokens + (rd32(index) * 4), cast(ptr, tok));
	store32(index, rd32(index) + 1);
}

proc token_type2str _type:int -> ptr {
	if(_type == Token_typeIdent) {
		return "`ident`";
	}
	elif(_type == Token_typeOpenParen) {
		return "`(`";
	}
	elif(_type == Token_typeCloseParen) {
		return "`)`";
	}
	elif(_type == Token_typeOpenCurly) {
		return "`{`";
	}
	elif(_type == Token_typeCloseCurly) {
		return "`}`";
	}
	elif(_type == Token_typeExit) {
		return "`exit`";
	}
	elif(_type == Token_typeIntLiteral) {
		return "`int literal`";
	}
	elif(_type == Token_typeSemi) {
		return "`;`";
	}
	elif(_type == Token_typePlus) {
		return "`+`";
	}
	elif(_type == Token_typeMinus) {
		return "`-`";
	}
	elif(_type == Token_typeStar) {
		return "`*`";
	}
	elif(_type == Token_typeSlash) {
		return "`/`";
	}
	elif(_type == Token_typePrint) {
		return "`print`";
	}
	elif(_type == Token_typeLet) {
		return "`let`";
	}
	elif(_type == Token_typeEq) {
		return "`=`";
	}
	elif(_type == Token_typeIf) {
		return "`if`";
	}
	elif(_type == Token_typeElif) {
		return "`elif`";
	}
	elif(_type == Token_typeElse) {
		return "`else`";
	}
	elif(_type == Token_typeProc) {
		return "`proc`";
	}
	elif(_type == Token_typeArrow) {
		return "`->`";
	}
	elif(_type == Token_typeVoid) {
		return "`void`";
	}
	elif(_type == Token_typeInt) {
		return "`int`";
	}
	elif(_type == Token_typeComma) {
		return "`,`";
	}
	elif(_type == Token_typeDoubleColon) {
		return "`:`";
	}
	elif(_type == Token_typeReturn) {
		return "`return`";
	}
	format_print("token_type2str error: unkown Token_type `%d`\n", _type);
	exit(0);
}

proc print_token tok:Token -> void {
	if(strlen(tok.value) != 0) {
		format_print("Token(%s, %s:%d:%d, %s)\n", token_type2str(tok._type), tok.file_loc, tok.line, tok.col, tok.value);
	} else {
		format_print("Token(%s, %s:%d:%d)\n", token_type2str(tok._type), tok.file_loc, tok.line, tok.col);
	}
}

proc print_tokens tokens:ptr -> void {
	let i = 0;
	while(rd32(tokens + (i * 4)) != 0) {
		let tok = cast(Token, rd32(tokens + (i * 4)));
		print_token(tok);
		i = i + 1;
	}
}

proc lexer_lex
	lxr:lexer
	str_arena:ArenaAllocator
	tokens:ptr
	FILE_PATH:ptr
-> void 
{
	let tokens_count = 0;
	let line_count = 1;
	let tmp_tok: Token;
	let tmp_str = new_tmp_str(str_arena, 56);
	while(lexer_peek(lxr) != NULL_PEEK) {
		if(is_identif(lexer_peek(lxr))) {
			while(is_identif(lexer_peek(lxr))) {
				tmp_str_push(tmp_str, lexer_consume(lxr));
			}
			if(streq(tmp_str.data, "exit")) {
				tmp_tok = Token(Token_typeExit, line_count, lxr.col - strlen(tmp_str.data), "", FILE_PATH);
				push_token(tokens, &tokens_count, tmp_tok);
			}
			elif(streq(tmp_str.data, "print")) {
				tmp_tok = Token(Token_typePrint, line_count, lxr.col - strlen(tmp_str.data), "", FILE_PATH);
				push_token(tokens, &tokens_count, tmp_tok);
			}
			elif(streq(tmp_str.data, "let")) {
				tmp_tok = Token(Token_typeLet, line_count, lxr.col - strlen(tmp_str.data), "", FILE_PATH);
				push_token(tokens, &tokens_count, tmp_tok);
			}
			elif(streq(tmp_str.data, "if")) {
				tmp_tok = Token(Token_typeIf, line_count, lxr.col - strlen(tmp_str.data), "", FILE_PATH);
				push_token(tokens, &tokens_count, tmp_tok);
			}
			elif(streq(tmp_str.data, "else")) {
				tmp_tok = Token(Token_typeElse, line_count, lxr.col - strlen(tmp_str.data), "", FILE_PATH);
				push_token(tokens, &tokens_count, tmp_tok);
			}
			elif(streq(tmp_str.data, "elif")) {
				tmp_tok = Token(Token_typeElif, line_count, lxr.col - strlen(tmp_str.data), "", FILE_PATH);
				push_token(tokens, &tokens_count, tmp_tok);
			}
			elif(streq(tmp_str.data, "proc")) {
				tmp_tok = Token(Token_typeProc, line_count, lxr.col - strlen(tmp_str.data), "", FILE_PATH);
				push_token(tokens, &tokens_count, tmp_tok);
			}
			elif(streq(tmp_str.data, "void")) {
				tmp_tok = Token(Token_typeVoid, line_count, lxr.col - strlen(tmp_str.data), "", FILE_PATH);
				push_token(tokens, &tokens_count, tmp_tok);
			}
			elif(streq(tmp_str.data, "int")) {
				tmp_tok = Token(Token_typeInt, line_count, lxr.col - strlen(tmp_str.data), "", FILE_PATH);
				push_token(tokens, &tokens_count, tmp_tok);
			}
			elif(streq(tmp_str.data, "return")) {
				tmp_tok = Token(Token_typeReturn, line_count, lxr.col - strlen(tmp_str.data), "", FILE_PATH);
				push_token(tokens, &tokens_count, tmp_tok);
			}
			else {
				tmp_tok = Token(Token_typeIdent, line_count, lxr.col - strlen(tmp_str.data), tmp_str.data, FILE_PATH);
				push_token(tokens, &tokens_count, tmp_tok);
			}
			tmp_str_realloc(tmp_str, str_arena, 56);
		}
		elif((lexer_peek(lxr) == '-') && (lexer_peek_at(lxr, 1) == '>')) {
			tmp_tok = Token(Token_typeArrow, line_count, lxr.col - 1, "", FILE_PATH);
			push_token(tokens, &tokens_count, tmp_tok);
			lexer_consume(lxr);
			lexer_consume(lxr);
		}
		elif(lexer_peek(lxr) == '(') {
			tmp_tok = Token(Token_typeOpenParen, line_count, lxr.col - 1, "", FILE_PATH);
			push_token(tokens, &tokens_count, tmp_tok);
			lexer_consume(lxr);
		}
		elif(lexer_peek(lxr) == ')') {
			tmp_tok = Token(Token_typeCloseParen, line_count, lxr.col - 1, "", FILE_PATH);
			push_token(tokens, &tokens_count, tmp_tok);
			lexer_consume(lxr);
		}
		elif(lexer_peek(lxr) == '{') {
			tmp_tok = Token(Token_typeOpenCurly, line_count, lxr.col - 1, "", FILE_PATH);
			push_token(tokens, &tokens_count, tmp_tok);
			lexer_consume(lxr);
		}
		elif(lexer_peek(lxr) == '}') {
			tmp_tok = Token(Token_typeCloseCurly, line_count, lxr.col - 1, "", FILE_PATH);
			push_token(tokens, &tokens_count, tmp_tok);
			lexer_consume(lxr);
		}
		elif(lexer_peek(lxr) == ';') {
			tmp_tok = Token(Token_typeSemi, line_count, lxr.col - 1, "", FILE_PATH);
			push_token(tokens, &tokens_count, tmp_tok);
			lexer_consume(lxr);
		}
		elif(lexer_peek(lxr) == ',') {
			tmp_tok = Token(Token_typeComma, line_count, lxr.col - 1, "", FILE_PATH);
			push_token(tokens, &tokens_count, tmp_tok);
			lexer_consume(lxr);
		}
		elif(lexer_peek(lxr) == ':') {
			tmp_tok = Token(Token_typeDoubleColon, line_count, lxr.col - 1, "", FILE_PATH);
			push_token(tokens, &tokens_count, tmp_tok);
			lexer_consume(lxr);
		}
		elif(lexer_peek(lxr) == '+') {
			tmp_tok = Token(Token_typePlus, line_count, lxr.col - 1, "", FILE_PATH);
			push_token(tokens, &tokens_count, tmp_tok);
			lexer_consume(lxr);
		}
		elif(lexer_peek(lxr) == '-') {
			tmp_tok = Token(Token_typeMinus, line_count, lxr.col - 1, "", FILE_PATH);
			push_token(tokens, &tokens_count, tmp_tok);
			lexer_consume(lxr);
		}
		elif(lexer_peek(lxr) == '*') {
			tmp_tok = Token(Token_typeStar, line_count, lxr.col - 1, "", FILE_PATH);
			push_token(tokens, &tokens_count, tmp_tok);
			lexer_consume(lxr);
		}
		elif(lexer_peek(lxr) == '=') {
			tmp_tok = Token(Token_typeEq, line_count, lxr.col - 1, "", FILE_PATH);
			push_token(tokens, &tokens_count, tmp_tok);
			lexer_consume(lxr);
		}
		elif(lexer_peek(lxr) == '/') {
			tmp_tok = Token(Token_typeSlash, line_count, lxr.col - 1, "", FILE_PATH);
			push_token(tokens, &tokens_count, tmp_tok);
			lexer_consume(lxr);
		}
		elif(isdigit(lexer_peek(lxr))) {
			while(isdigit(lexer_peek(lxr))) {
				tmp_str_push(tmp_str, lexer_consume(lxr));
			}
			tmp_tok = Token(Token_typeIntLiteral, line_count, lxr.col - strlen(tmp_str.data), tmp_str.data, FILE_PATH);
			push_token(tokens, &tokens_count, tmp_tok);
			tmp_str_realloc(tmp_str, str_arena, 56);
		}
		elif(lexer_peek(lxr) == '\n') {
			line_count = line_count + 1;
			lxr.col = 1;
			lexer_consume(lxr);
		}
		elif(isspace(lexer_peek(lxr))) {
			while(isspace(lexer_peek(lxr))) {
				lexer_consume(lxr);
			}
		}
		else {
			if(lexer_peek(lxr) != 0) {
				format_print("%s:%d:%d ERROR: invalid token\n", FILE_PATH, line_count, lxr.col);
				exit(1);
			}
			lexer_consume(lxr); // 0 byte
		}
	}
	store32(tokens + (tokens_count * 4), 0);
}