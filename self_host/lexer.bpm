include "std"
include "self_host/arena"
include "string"
include "string_view"

struct lexer {
	src:StringView,
	index:int,
	col:int
}

proc new_lexer src:ptr -> lexer {
	let src_sv = sv_from(src);
	return lexer(src_sv, 0, 1);
}

proc lexer_delete lxr:lexer -> void {
	delete lxr.src;
	delete lxr;
}

proc lexer_consume lxr:lexer -> int {
	let chr = sv_at(lxr.src, lxr.index);
	lxr.index = lxr.index + 1;
	lxr.col = lxr.col + 1;
	return chr;
}

const NULL_PEEK 4294967295;

proc lexer_peek lxr:lexer -> int {
	if(lxr.index > lxr.src.count) {
		return NULL_PEEK;
	}
	return sv_at(lxr.src, lxr.index);
}

proc lexer_peek_at lxr:lexer offs:int -> int {
	if((lxr.index + offs) > lxr.src.count) {
		return NULL_PEEK;
	}
	return sv_at(lxr.src, lxr.index + offs);
}

struct TmpStr {
	used:int,
	capacity:int,
	data:ptr
}

proc new_tmp_str arena:ArenaAllocator size:int -> TmpStr {
	return TmpStr(0, size, arena_take(arena, size));
}

proc tmp_str_push str:TmpStr chr:int -> void {
	store8(str.data + str.used, chr);
	str.used = str.used + 1;
	store8(str.data + str.used, 0);
}

proc isspace chr:int -> int {
	if(chr == ' ') {
		return true;
	}
	return false;
}

proc isdigit chr:int -> int {
	if(chr > ('0' - 1)) {
		if(chr < ('9' + 1)) {
			return true;
		}
		return false;
	}
	else {
		return false;
	}
}

proc is_identif chr:int -> int {
	if(chr == '_') {
		return true;
	}
	if(chr < 'A') {
		return false;
	}
	if(chr > 'z') {
		return false;
	}
	if(chr > 'Z') {
		if(chr < 'a') {
			return false;
		}
	}
	return true;
}

const TokenTypeIdent 0;
const TokenTypeOpenParen 1;
const TokenTypeCloseParen 2;
const TokenTypeExit 3;
const TokenTypeIntLiteral 4;
const TokenTypeSemi 5;

struct Token {
	type:int,
	line:int,
	col:int,
	value:ptr
}

proc push_token tokens:ptr index:ptr tok:Token -> void {
	store32(tokens + (rd32(index) * 4), cast(ptr, tok));
	store32(index, rd32(index) + 1);
}

proc ptr_to_tok p:ptr -> Token {
	asm "push dword [ebp-4]";
}

proc tokentype2str type:int -> ptr {
	if(type == TokenTypeIdent) {
		return "`ident`";
	}
	elif(type == TokenTypeOpenParen) {
		return "`(`";
	}
	elif(type == TokenTypeCloseParen) {
		return "`)`";
	}
	elif(type == TokenTypeExit) {
		return "`exit`";
	}
	elif(type == TokenTypeOpenParen) {
		return "`(`";
	}
	elif(type == TokenTypeIntLiteral) {
		return "`int literal`";
	}
	elif(type == TokenTypeOpenParen) {
		return "`(`";
	}
	elif(type == TokenTypeSemi) {
		return "`;`";
	}
	format_print("tokentype2str error: unkown TokenType `%d`\n", type);
	exit(0);
}

proc print_token tok:Token -> void {
	if(strlen(tok.value) != 0) {
		format_print("Token(%s, %d:%d, %s)\n", tokentype2str(tok.type), tok.line, tok.col, tok.value);
	} else {
		format_print("Token(%s, %d:%d)\n", tokentype2str(tok.type), tok.line, tok.col);
	}
}

proc print_tokens tokens:ptr -> void {
	let i = 0;
	while(rd32(tokens + (i * 4)) != 0) {
		let tok = cast(Token, rd32(tokens + (i * 4)));
		print_token(tok);
		i = i + 1;
	}
}

proc free_tokens tokens:ptr -> void {
	let i = 0;
	while(rd32(tokens + (i * 4)) != 0) {
		let tok = cast(Token, rd32(tokens + (i * 4)));
		delete tok;
		i = i + 1;
	}
	memfree(tokens);
}

proc lexer_lex
	lxr:lexer
	str_arena:ArenaAllocator
	tokens:ptr
-> void 
{
	let tokens_count = 0;
	let line_count = 1;
	let tmp_tok = Token(TokenTypeIdent, 0, 0, "");
	delete tmp_tok;
	let tmp_str = new_tmp_str(str_arena, 56);
	while(lexer_peek(lxr) != NULL_PEEK) {
		if(is_identif(lexer_peek(lxr))) {
			while(is_identif(lexer_peek(lxr))) {
				tmp_str_push(tmp_str, lexer_consume(lxr));
			}
			if(streq(tmp_str.data, "exit")) {
				tmp_tok = Token(TokenTypeExit, line_count, lxr.col - strlen(tmp_str.data), "");
				push_token(tokens, &tokens_count, tmp_tok);
			}
			else {
				tmp_tok = Token(TokenTypeIdent, line_count, lxr.col - strlen(tmp_str.data), tmp_str.data);
				push_token(tokens, &tokens_count, tmp_tok);
			}
			tmp_str = new_tmp_str(str_arena, 56);
		}
		elif(lexer_peek(lxr) == '(') {
			tmp_tok = Token(TokenTypeOpenParen, line_count, lxr.col - 1, "");
			push_token(tokens, &tokens_count, tmp_tok);
			lexer_consume(lxr);
		}
		elif(lexer_peek(lxr) == ')') {
			tmp_tok = Token(TokenTypeCloseParen, line_count, lxr.col - 1, "");
			push_token(tokens, &tokens_count, tmp_tok);
			lexer_consume(lxr);
		}
		elif(lexer_peek(lxr) == ';') {
			tmp_tok = Token(TokenTypeSemi, line_count, lxr.col - 1, "");
			push_token(tokens, &tokens_count, tmp_tok);
			lexer_consume(lxr);
		}
		elif(isdigit(lexer_peek(lxr))) {
			while(isdigit(lexer_peek(lxr))) {
				tmp_str_push(tmp_str, lexer_consume(lxr));
			}
			tmp_tok = Token(TokenTypeIntLiteral, line_count, lxr.col - strlen(tmp_str.data), tmp_str.data);
			push_token(tokens, &tokens_count, tmp_tok);
			tmp_str = new_tmp_str(str_arena, 56);
		}
		elif(lexer_peek(lxr) == '\n') {
			line_count = line_count + 1;
			lexer_consume(lxr);
		}
		elif(isspace(lexer_peek(lxr))) {
			while(isspace(lexer_peek(lxr))) {
				lexer_consume(lxr);
			}
		}
		else {
			lexer_consume(lxr);
		}
	}
	store32(tokens + (tokens_count * 4), 0);
	print_tokens(tokens);
}